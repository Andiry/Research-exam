\section{Introduction}
\label{sec:introduction}

Emerging non-volatile memories such as spin-torque transfer RAM (STT-RAM),
phase change memory (PCM), and
memristor-based memories~\cite{moneta, monetad, quicksan,Onyx,
pollisbetterthaninterrupt}
promise to revolutionize I/O performance and how
systems manage and provide access to persistent state.
Table~\ref{table:techtrend}
shows the characteristics of these NVM technologies. The most aggressive
proposals for integrating these technologies place them on the processor's
memory bus alongside or replacing conventional DRAM, leading to non-volatile
main memory (NVMM)-based systems~\cite{PCM_EfficientMainMemory,
PCMHierarchy,eNVy,WSP}. The close coupling of compute and
non-volatility in NVMM systems will force system designers to rethink how
software interacts with storage, if applications are going to reap the benefits of NVMM.

Traditional software stack to access storage device such as disks
adds software overhead such as mode switch, block layer and I/O scheduling.
As disk access time dominates the latency, software overhead is trivial.
However, with low-latency NVMM, software overheads play an important role
in the access latency~\cite{monetad,BankShot}. Traditional software
stack is not suitable for fast NVMM and we need a new software accessing model.

On the other hand, as NVMM provides latency and bandwidth comparable to DRAM,
new problems
appear if the processors directly access them as DRAM. One problem is 
CPU cache hierarchy. Modern CPUs have several levels of write-back cache,
 and data store does not flush to memory explicitly. If system fails before
data in cache flushed to NVMM, the data is lost after
recovery~\cite{CPUcaching}. Another
problem is the write reordering, as modern CPU may reorder writes to the
memory for performance, and use cache consistency protocols to maintain
a consistent visibility of memory for the processors. However, for NVMM,
out-of-order writes may break the consistency after the system failure,
for example, in file system if the metadata change is written to NVMM before
the file data, the file may be corrupted if system fails during the two 
operations. 

NVMMs invite a range of different interface designs, depending on the amount of
NVMM available, the scale of the overall storage system, and the need (or lack
thereof) to support legacy applications.  Researchers have proposed architecting
NVMM as DRAM extension~\cite{pdram, memorage, duet}, specialized
file systems for NVMMs~\cite{PMFS,BPFS}, non-volatile
caches~\cite{RVM,riofilecache,riovista}, and new programming
models~\cite{nvheaps,mnemosyne}.

The remainder of the paper is organized as follows. Section
~\ref{sec:background} introduces the background on the NVMM technologies.
Section~\ref{sec:fs} discusses the NVMM file system design principles and
challenges.
Section~\ref{sec:access} shows the programming models to access NVMM
efficiently.
Section~\ref{sec:migration} introduces the design of systems with both DRAM and NVMM, and in Section~\ref{sec:caching} we show the systems that use NVMM as a
 cache to accelerate storage access.
Section~\ref{sec:related} introduces
related NVMM work and Section~\ref{sec:future} explores the impact of NVMM
on future system designs. Finally
 Section~\ref{sec:conclude} summarizes our conclusion.



\ignore{
However, these interfaces will only
be successful if they can provide access to NVMM without sacrificing the
performance it can provide.

In this work we present \emph{\Chell{}}, a system that uses NVMM to accelerate
access to file data.  \Chell{} operates in two modes: The first mode,
\emph{\DAChell{}}, targets systems that store entire file systems in NVMM.  These might
include future mobile systems or servers with large NVMM capacity.  The goal of
\DAChell{} is to provide direct access to file contents without incurring the
substantial latencies that operating and file system-mediated access impose.

\DAChell{} achieves this by transparently replacing conventional system calls
with memory operations: In response to \texttt{open()}, \DAChell{} memory maps
the physical pages
that make up the file directly into the application's address space and can
then implement calls to \texttt{read()} and \texttt{write()} with userspace
memory-to-memory copy operations.  \DAChell{} is implemented as a userspace
library, \emph{\libd{}}, that dynamically links into the application and interposes on
system calls.  As a result, it requires neither modification nor re-compilation of the application.

The second approach, \CChell{}, focuses on systems that must access large
storage volumes and are equipped with modest amounts of NVMM.  \CChell{}
provides these systems with an NVMM-based persistent, write-back cache of a
larger, conventional storage volume.  

\CChell{} builds upon \DAChell{} by adding a kernel module that caches the contents
of a conventional file system in the system's NVMM.  The \CChell{} kernel module,
\emph{\drv{}}, manages and maintains the cache while the \CChell{} userspace library,
\emph{\lib{}}, provides direct access to the cached contents.

This paper describes and evaluates both of \Chell{}'s modes.  It examines the
design challenges that each one presents and explains the motivation for the
design decisions we made.  We evaluate both systems using a combination of
micro- and macro-benchmarks and find that comparing to PMFS~\cite{PMFS},
\DAChell{} reduces 4~KB read/write latency by 19\% and improves Berkeley-DB
throughput by 6\%. \CChell{} reduces 4~KB access latency by 35\% for reads
50\% for writes, and improves Berkeley-DB throughput by up to 4.8\x{} over Linux page cache.

We also use the results to illustrate the negative impact that legacy
file-based interfaces impose, and, based on these findings, we propose changes
that would allow for simpler, faster access to file data.  These changes would
allows applications to more fully benefit from NVMM performance without
requiring invasive changes in how they access and manage non-volatile data.
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
